salloc --ntasks=1 --time=01:59:59 --gres=gpu:1 --partition=q1m_2h-1G

salloc --ntasks=1 --time=11:59:59 --gres=gpu:2 --partition=q2h_12h-2G

salloc --ntasks=1 --time=47:59:59 --gres=gpu:1 --partition=q2h_48h-2G

salloc --ntasks=1 --time=47:59:59 --gres=gpu:1 --partition=cl1_all_4G

salloc --ntasks=1 --time=47:59:59 --gres=gpu:1 --partition=cl1_48h-1G

salloc --ntasks=1 --time=47:59:59 --gres=gpu:1 --partition=cl2_48h-1G

salloc --ntasks=1 --time=47:59:59 --gres=gpu:4 --partition=cl2_all_8G

salloc --ntasks=1 --time=48:59:59 --partition=cl1_all_64C

docker run --runtime=nvidia -it ${USE_TTY} --ipc=host --name $SLURM_JOB_ID --rm -v /scratch/bhargavs:/workspace ptt:latest

install apex in container

export CUDA_VISIBLE_DEVICES=0,1,2,3
or 
export CUDA_VISIBLE_DEVICES=4,5,6,7

=================================================================
Supervised
=================================================================
# AdamW, trainable LSTM initial states

python train_supervised.py --save_dir /home/bhargav/projects/speed_reading_results/trial/ --train_batch_size 100 --dev_batch_size 100 --lr 1e-3 --epochs 50 --max_grad_norm 0.1 --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 50 --save_every 200 --early_stopping_patience 10 --data_loader_num_workers 8 --model_to_use 1 --optimizer adamw

Best dev metrics: 0.88392


# RMSProp, LSTM initial states set to 0

python train_supervised.py --save_dir /home/bhargav/projects/speed_reading_results/sup2/ --train_batch_size 100 --dev_batch_size 100 --lr 5e-4 --epochs 50 --max_grad_norm 0.1 --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 50 --save_every 200 --early_stopping_patience 10 --data_loader_num_workers 8 --model_to_use 1 --optimizer rmsprop


=================================================================
RL 
=================================================================

python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl1/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 100 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/trial/best.pt --rl_algo ac --epochs 100 --optimizer adamw

After 85 epochs. Read fraction is NOT converging:
Best dev metrics: {'classification_accuracy': 0.86264, 'avg_read_fraction': 0.7615777850151062}.



python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl1/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 100 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/trial/best.pt --rl_algo ac --epochs 100 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 1.0 --loss_weight_entropy 0.0 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 1.0 --optimizer adamw



python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl2/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 100 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/trial/best.pt --rl_algo ac --epochs 100 --loss_weight_actor 5.0 --optimizer adamw

read fraction increased to ~70-80%. Accuracy was around 85%


# RMSProp, LSTM initial states are 0


python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl3/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.5 --optimizer rmsprop

classification_accuracy: 83%
Read fraction: ~5%



python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl4/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.5 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.5 --optimizer rmsprop

classification_accuracy: ~84%
Read fraction: ~6%



python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl5/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.5 --optimizer rmsprop --train_word_embeddings

classification_accuracy: 82-83%
Read fraction: 6%



python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl6/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.3 --optimizer rmsprop --train_word_embeddings

classification_accuracy: 82-83%
Read fraction: 5-10%


python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl7/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.4 --optimizer rmsprop --train_word_embeddings

max: 85% acc with 16% read


python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl8/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.5 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.4 --optimizer rmsprop --train_word_embeddings

classification_accuracy: 84-85%
Read fraction: 8-15%


# on t1
# same as rl7. running again for plots
python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl9/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.4 --optimizer rmsprop


------------------------------------------------
Cross entropy loss between action distribution and [0.5,0.5]

# on t2
# same as rl7 but with different entropy loss
python train_rl.py --save_dir /home/bhargav/projects/speed_reading_results/rl10/ --training_data ../preprocessed_data/preprocessed_train.pkl --dev_data ../preprocessed_data/preprocessed_test.pkl --embedding_matrix ../preprocessed_data/embedding_matrix.npy --log_every 5 --save_every 200 --early_stopping_patience 1000 --data_loader_num_workers 8 --model_to_use 1 --warm_start_checkpoint /home/bhargav/projects/speed_reading_results/sup2/best.pt --rl_algo ac --epochs 200 --loss_weight_actor 1.0 --loss_weight_critic 1.0 --loss_weight_classification 0.3 --loss_weight_entropy 0.01 --sent_skip_reward_multiplier 0.5 --step_reward_multiplier 0.4 --optimizer rmsprop --entropy_loss_type 2





=================================================================
Self training, no RL 
=================================================================

python train_self_training.py --save_dir /home/bhargav/projects/speed_reading_results/st_trial/ --training_data ../preprocessed_data/semi_supervised/preprocessed_train.pkl --dev_data ../preprocessed_data/semi_supervised/preprocessed_val.pkl --embedding_matrix ../preprocessed_data/semi_supervised/embedding_matrix.npy --log_every 5 --model_to_use 1 --optimizer rmsprop --patience_for_adding_data 4 --patience_before_adding_data 6 --pseudo_label_threshold 0.9




python train_self_training.py --save_dir /home/bhargav/projects/speed_reading_results/st1/ --training_data ../preprocessed_data/semi_supervised/preprocessed_train.pkl --dev_data ../preprocessed_data/semi_supervised/preprocessed_val.pkl --embedding_matrix ../preprocessed_data/semi_supervised/embedding_matrix.npy --log_every 5 --model_to_use 1 --optimizer rmsprop --patience_for_adding_data 4 --patience_before_adding_data 6 --pseudo_label_threshold 0.9


------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------